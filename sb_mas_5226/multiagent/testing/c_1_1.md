# A - Make GridWorld

# B - make locations
## B.b assign them to grid

# C - Make the actions
## C.c have agent see all adjacent cells

# D - Make reward vector

"""Make reward vector"""        
        rewards = np.full((self.grid_cols, self.grid_cols), -1)  # Default: -1 for valid move
        rewards[self.a[0], self.a[1]] = 1             # Goal cell
        # For walls, you may encode -2 dynamically during invalid transitions

# E - make transitions
## if at one location, then set goal to other location

# E - Make the Q-table
## must have nums (n size, n size goal location size, moves, bool of reached goal)

# F - Make on-policy algorithm

# G - make off-policy to evaluate on-policy

# <X> Satisfy the BEE in on-policy

# <X> satisfy the BOE in off-policy